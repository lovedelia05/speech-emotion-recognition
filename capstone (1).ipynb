{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5go7XOAjStc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#!pip install librosa\n",
        "#!pip install tensorflow\n",
        "import librosa\n",
        "import librosa.display\n",
        "import soundfile as sf\n",
        "import random\n",
        "import configparser\n",
        "import math\n",
        "#import tensorflow as tf\n",
        "#import utility_functions as uf\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Audio\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install audiomentations\n",
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neBKNuonkZFA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHcDK3zVkk_n"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/extracted_features_with_labels.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03i8is0-kxTe"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRi79cNek0r_"
      },
      "outputs": [],
      "source": [
        "df['Emotion'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5NrzQ_-mL7W"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert emotion labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "df['emotion_encoded'] = label_encoder.fit_transform(df['Emotion'])\n",
        "\n",
        "Y = df['emotion_encoded'].values\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "#encoder = OneHotEncoder()\n",
        "#Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLedUu5Ce9FE"
      },
      "outputs": [],
      "source": [
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP-l4dzoqrUo"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['emotion_encoded','Emotion'],axis=1)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMfVrDHDqlU2"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "# Print the shapes of the resulting sets\n",
        "print(\"Training set features shape:\", X_train.shape)\n",
        "print(\"Testing set features shape:\", X_test.shape)\n",
        "print(\"Training set labels shape:\", y_train.shape)\n",
        "print(\"Testing set labels shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCWUw5c_dAgQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_hQdv-_1JQD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming your data is in a pandas DataFrame `df`\n",
        "# Separate features and labels\n",
        "X = df.iloc[:, :-1]  # Features (all columns except 'emotion')\n",
        "y = df['Emotion']    # Emotion labels (last column)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qqIyX3e4Uz8"
      },
      "outputs": [],
      "source": [
        "X.drop('Emotion', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX2y5zwU4MDJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Encode the emotion labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# List of unique emotions\n",
        "emotions = label_encoder.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acHp5-rQ4djI"
      },
      "outputs": [],
      "source": [
        "y_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbyQ4-wu4FSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb0632d-1c76-4794-cd62-dbe609c6d81c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for emotion: angry\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96      1613\n",
            "           1       0.81      0.56      0.66       231\n",
            "\n",
            "    accuracy                           0.93      1844\n",
            "   macro avg       0.88      0.77      0.81      1844\n",
            "weighted avg       0.92      0.93      0.92      1844\n",
            "\n",
            "Results for emotion: calm\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95      1621\n",
            "           1       0.70      0.53      0.60       223\n",
            "\n",
            "    accuracy                           0.92      1844\n",
            "   macro avg       0.82      0.75      0.78      1844\n",
            "weighted avg       0.91      0.92      0.91      1844\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## One-vs-All Classification\n",
        "for emotion in emotions:\n",
        "  # Create binary labels for one-vs-all classification (1 for the current emotion, 0 for others)\n",
        "  y_bin = np.where(y_encoded == label_encoder.transform([emotion])[0], 1, 0)\n",
        "\n",
        "    #Split data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Train binary classifier\n",
        "  clf = SVC(kernel='linear', probability=True)\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and evaluate\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(f\"Results for emotion: {emotion}\")\n",
        "  print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5buKiWU6F_8"
      },
      "outputs": [],
      "source": [
        "!pip install shap\n",
        "import shap\n",
        "    Apply SHAP (use only if you have a model and data available)\n",
        "#SHAP requires a fitted model and the data used to train the model\n",
        "explainer = shap.Explainer(clf, X_train)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "    # Plot SHAP values for the current emotion\n",
        "shap.summary_plot(shap_values, X_test, feature_names=X.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPhc6mD-yEbP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# Filter for 5 emotions: Angry, Neutral, Calm, fearful, Surprised\n",
        "emotions_to_keep = ['angry', 'neutral', 'calm', 'fearful', 'surprised']\n",
        "filtered_data = df[df['emotion'].isin(emotions_to_keep)]\n",
        "\n",
        "# Map emotions to integers if not already\n",
        "emotion_map = {emotion: idx for idx, emotion in enumerate(emotions_to_keep)}\n",
        "filtered_data['emotion'] = filtered_data['emotion'].map(emotion_map)\n",
        "\n",
        "# Split features and labels\n",
        "X = filtered_data.drop(columns=['emotion','emotion_encoded'])\n",
        "y = filtered_data['emotion']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZS4ozBu-ZrRE"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiaeHr0sY_62"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qujG4t8wZQC7"
      },
      "outputs": [],
      "source": [
        "y.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ2XF6fKJLsn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlVJeqEawkvN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('svm', SVC(kernel='linear', probability=True)),\n",
        "    ('rf', RandomForestClassifier()),\n",
        "    ('logreg', LogisticRegression())\n",
        "]\n",
        "\n",
        "# Define meta-model\n",
        "meta_model = LogisticRegression()\n",
        "\n",
        "# Create the stacking ensemble\n",
        "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
        "\n",
        "# Train the stacking ensemble model\n",
        "stacking_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_test_pred = stacking_clf.predict(X_test_scaled)\n",
        "y_train_pred = stacking_clf.predict(X_train_scaled)\n",
        "\n",
        "# Calculate accuracy for training and testing sets\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "# Plotting the confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "\n",
        "# Bar plot for precision, recall, and F1-score\n",
        "metrics_df = pd.DataFrame(report).transpose()\n",
        "metrics_df.drop(['support'], axis=1, inplace=True)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "metrics_df.iloc[:-1].plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Classification Report Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Metrics')\n",
        "plt.show()\n",
        "\n",
        "# Plotting Learning Curves\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    stacking_clf, X_train_scaled, y_train, cv=5, n_jobs=-1,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10)\n",
        ")\n",
        "\n",
        "# Calculate the mean and std for train and test scores\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "train_scores_std = np.std(train_scores, axis=1)\n",
        "test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plotting Learning Curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\n",
        "plt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')\n",
        "\n",
        "# Plot the std deviation as shaded area\n",
        "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                 train_scores_mean + train_scores_std, color='r', alpha=0.1)\n",
        "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                 test_scores_mean + test_scores_std, color='g', alpha=0.1)\n",
        "\n",
        "plt.title('Learning Curves')\n",
        "plt.xlabel('Training Examples')\n",
        "plt.ylabel('Score')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "iFIElUnmdbdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eud55n7TITn"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(stacking_clf, 'Support_Vector_Machine_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1J62CUgNYTf"
      },
      "outputs": [],
      "source": [
        "# Load your saved SVM model\n",
        "model = joblib.load('Support_Vector_Machine_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXsQFRIZRm4s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize KNN with k=5 (you can tune this)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train KNN model\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = knn.predict(X_train_scaled)\n",
        "y_test_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix for KNN')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcp7xruxYot8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "import shap\n",
        "    # Apply SHAP (use only if you have a model and data available)\n",
        "#SHAP requires a fitted model and the data used to train the model\n",
        "explainer = shap.Explainer(stacking_clf, X_train)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "    # Plot SHAP values for the current emotion\n",
        "shap.summary_plot(shap_values, X_test, feature_names=X.columns)\n"
      ],
      "metadata": {
        "id": "erWclxIKXJ7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BeZyr6cVRKM"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# PCA for dimensionality reduction to 2D\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# Scatter plot of the PCA-reduced training data\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.colorbar()\n",
        "plt.title(\"2D PCA Visualization of Speech Emotion Data (Training Set)\")\n",
        "plt.xlabel(\"PCA Component 1\")\n",
        "plt.ylabel(\"PCA Component 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HNZX5ljVneE"
      },
      "outputs": [],
      "source": [
        "# Optional: Use t-SNE for a more complex visualization\n",
        "tsne = TSNE(n_components=2)\n",
        "X_train_tsne = tsne.fit_transform(X_train_scaled)\n",
        "\n",
        "# Scatter plot of t-SNE reduced data\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], c=y_train, cmap='coolwarm', s=50, alpha=0.7)\n",
        "plt.colorbar()\n",
        "plt.title(\"2D t-SNE Visualization of Speech Emotion Data (Training Set)\")\n",
        "plt.xlabel(\"t-SNE Component 1\")\n",
        "plt.ylabel(\"t-SNE Component 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O2DNz2QbUUK"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Sample data\n",
        "report = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Heatmap visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df_report.iloc[:-1, :-1], annot=True, cmap='Blues', fmt=\".2f\")\n",
        "plt.title('Classification Report Heatmap')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "import shap\n",
        "    # Apply SHAP (use only if you have a model and data available)\n",
        "SHAP requires a fitted model and the data used to train the model\n",
        "explainer = shap.Explainer(, X_train)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "    # Plot SHAP values for the current emotion\n",
        "shap.summary_plot(shap_values, X_test, feature_names=X.columns)\n"
      ],
      "metadata": {
        "id": "OUkgEIBGW_dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Xf-eYYIcBpx"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "scatter = sns.scatterplot(x=X_train_tsne[:, 0], y=X_train_tsne[:, 1], hue=y_train, palette='Spectral', alpha=0.7)\n",
        "plt.title('2D t-SNE Visualization of Speech Emotion Data')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "\n",
        "# Create a colorbar based on the scatter plot\n",
        "norm = plt.Normalize(vmin=y_train.min(), vmax=y_train.max())\n",
        "sm = plt.cm.ScalarMappable(cmap='viridis', norm=norm)\n",
        "sm.set_array([])\n",
        "cbar = plt.colorbar(sm)\n",
        "cbar.set_label('Emotions')\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}